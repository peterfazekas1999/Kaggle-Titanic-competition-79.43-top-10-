{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DJw_JUBmdh1Q"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout,BatchNormalization\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from sklearn.preprocessing import scale,minmax_scale\n",
    "from tensorflow.keras import initializers, optimizers\n",
    "import io\n",
    "import requests\n",
    "import re\n",
    "import warnings\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from keras.regularizers import l2\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "df2 = df\n",
    "test_data = pd.read_csv(\"test.csv\")\n",
    "df_test=test_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    \n",
    "    #extract the title feature\n",
    "    def getMedian(df,name):\n",
    "        return df[df[\"Title\"]==name].Age.dropna().median()\n",
    "    \n",
    "    def replace_missing_age(df):\n",
    "        df.loc[(df[\"Age\"].isnull())&(df[\"Title\"]==\"Mr\"),\"Age\"] =  getMedian(df,\"Mr\") \n",
    "        df.loc[(df[\"Age\"].isnull())&(df[\"Title\"]==\"Miss\"),\"Age\"] =  getMedian(df,\"Miss\")\n",
    "        df.loc[(df[\"Age\"].isnull())&(df[\"Title\"]==\"Mrs\"),\"Age\"] =  getMedian(df,\"Mrs\")\n",
    "        df.loc[(df[\"Age\"].isnull())&(df[\"Title\"]==\"Master\"),\"Age\"] = getMedian(df,\"Master\")\n",
    "        df.loc[(df[\"Age\"].isnull())&(df[\"Title\"]==\"Rare\"),\"Age\"] =  getMedian(df,\"Rare\")\n",
    "        return df\n",
    "    \n",
    "    def title(df):\n",
    "        df['Title'] = df.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "        #print(df[\"Title\"].describe())\n",
    "        df['Title'] = df['Title'].replace(['Lady',\"Ms\",'Countess','Capt', 'Col',\\\n",
    " \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "        df = replace_missing_age(df)\n",
    "        map_title = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
    "        df[\"Title\"] = df[\"Title\"].map(map_title)\n",
    "        df[\"Title\"] = df[\"Title\"].fillna(1)\n",
    "        return df\n",
    "    \n",
    "    df = title(df)\n",
    "    \n",
    "    #dont need names and cabins had a lot of missing values so get rid of it\n",
    "    #also we dont need the ticket number\n",
    "    def drop_values(df):\n",
    "        df = df.drop(\"Cabin\",axis = 1)\n",
    "        df = df.drop(\"Name\",axis = 1)\n",
    "        df = df.drop(\"Ticket\",axis = 1)\n",
    "        return df\n",
    "    \n",
    "    df = drop_values(df)\n",
    "    \n",
    "    \n",
    "    genders = {\"male\":1,\"female\":0}\n",
    "    df[\"Sex\"] = df[\"Sex\"].map(genders)\n",
    "    \n",
    "    df[\"Embarked\"] = df[\"Embarked\"].fillna(\"S\")\n",
    "    \n",
    "    ports = {\"S\":0,\"C\":1,\"Q\":2}\n",
    "    \n",
    "    df[\"Embarked\"] = df[\"Embarked\"].map(ports)\n",
    "    \n",
    "    \n",
    "    def isalone(df):\n",
    "        df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "        df[\"isalone\"]=0\n",
    "        df.loc[df[\"FamilySize\"]==1,\"isalone\"]=1\n",
    "        #df.drop(\"FamilySize\",axis = 1)\n",
    "        return df\n",
    "    df = isalone(df)\n",
    "    def get_fares(df):\n",
    "        df.loc[df[\"Fare\"]<=7.91,\"Fare\"]=0\n",
    "        df.loc[(df[\"Fare\"]<=14)&(df[\"Fare\"]>7.91),\"Fare\"]=1\n",
    "        df.loc[(df[\"Fare\"]<=25)&(df[\"Fare\"]>14),\"Fare\"]=2\n",
    "        df.loc[(df[\"Fare\"]<=31)&(df[\"Fare\"]>25),\"Fare\"]=3\n",
    "        df.loc[(df[\"Fare\"]<=69)&(df[\"Fare\"]>31),\"Fare\"]=4\n",
    "        df.loc[(df[\"Fare\"]<=99)&(df[\"Fare\"]>69),\"Fare\"]=5\n",
    "        df.loc[(df[\"Fare\"]<=250)&(df[\"Fare\"]>99),\"Fare\"]=6\n",
    "        df.loc[df[\"Fare\"]>250,\"Fare\"]=7\n",
    "        return df\n",
    "    \n",
    "    def fare_pclass_feature(df):\n",
    "        df[\"fare*pclass\"] = df[\"Pclass\"]*df[\"Fare\"]\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    df.Fare = df.Fare.fillna(df.Fare.mean())\n",
    "    df = get_fares(df)\n",
    "    df = fare_pclass_feature(df)\n",
    "     \n",
    "    #categorises the age of the people\n",
    "    def categAge(df):\n",
    "        df.loc[df[\"Age\"]<=16,\"Age\"]=0\n",
    "        df.loc[(df[\"Age\"]>16) & (df[\"Age\"]<=32),\"Age\"] = 1\n",
    "        df.loc[(df[\"Age\"]>32) & (df[\"Age\"]<=48),\"Age\"] =2\n",
    "        df.loc[(df[\"Age\"]>48) & (df[\"Age\"]<=64),\"Age\"] =3\n",
    "        df.loc[(df[\"Age\"]>60),\"Age\"] =4\n",
    "        return df\n",
    "    df = categAge(df)\n",
    "    return df\n",
    "\n",
    "df = preprocess(df)\n",
    "df_prescaled = df.copy()\n",
    "\n",
    "def scaler_fun(df):\n",
    "    #data scaling\n",
    "    df_scaled = df.drop(\"Survived\",axis = 1)\n",
    "    df_scaled = scale(df_scaled)\n",
    "    #df_scaled = minmax_scale(df_scaled)\n",
    "    cols = df.columns.tolist()\n",
    "    cols.remove(\"Survived\")\n",
    "    df_scaled = pd.DataFrame(df_scaled,columns = cols,index = df.index)\n",
    "    df_scaled = pd.concat([df_scaled,df[\"Survived\"]],axis = 1)\n",
    "    df = df_scaled.copy()\n",
    "    return df\n",
    "\n",
    "pass_id_train = df[\"PassengerId\"].copy()\n",
    "df = scaler_fun(df)\n",
    "X = df.loc[:, (df.columns != \"Survived\") & (df.columns != \"PassengerId\")]\n",
    "Y = df.loc[:,\"Survived\"]\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size = 0.1,random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64,activation = \"relu\",input_dim= X.shape[1],kernel_initializer=\"normal\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(32,activation = \"relu\",kernel_initializer=\"normal\"))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(16,activation = \"relu\",kernel_initializer=\"normal\"))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(16,activation = \"relu\",kernel_initializer=\"normal\"))\n",
    "model.add(Dense(1,activation = \"sigmoid\"))\n",
    "adam = Adam(learning_rate = 2E-4)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer = adam,metrics = [\"accuracy\"])\n",
    "callback = keras.callbacks.EarlyStopping(monitor='loss',patience=25)\n",
    "history = model.fit(x_train,y_train,validation_data=(x_test,y_test),epochs = 1000,batch_size=801,callbacks = [callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the Hyperparameter search function, I have used it but I found that changing the parameters by hand worked better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(learning_rate = 3E-4)\n",
    "def create_model(dropout=0.3,init=\"glorot_normal\",optimizer=adam):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64,activation = \"relu\",input_dim= X.shape[1],kernel_initializer=init))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(32,activation = \"relu\",kernel_initializer=init))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(16,activation = \"relu\",kernel_initializer=init))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(16,activation = \"relu\",kernel_initializer=init))\n",
    "    model.add(Dense(1,activation = \"sigmoid\"))\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer = optimizer,metrics = [\"accuracy\"])\n",
    "    return model\n",
    "#standard setup for the Gridsearch to find Hyperparameters\n",
    "def gridsearch_fun():\n",
    "    model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "    batch_size = [400,550,800]\n",
    "    epochs = [300,500,600]\n",
    "    init = ['glorot_uniform', 'normal']\n",
    "    optimizer = [\"Adagrad\",\"Adam\"]\n",
    "    param_grid = dict(batch_size=batch_size, epochs=epochs,init = init,dropout=[0.1,0.2,0.3,0.4],optimizer = optimizer)\n",
    "    grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "    grid_result = grid.fit(X,Y)\n",
    "    # summarize results\n",
    "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    for mean, stdev, param in zip(means, stds, params):\n",
    "        print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "gridsearch_fun()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_before = df_test.copy()\n",
    "df_test =preprocess(df_test)\n",
    "passenger_id = df_test[\"PassengerId\"].copy()\n",
    "def scaler_fun2(df):\n",
    "    #data scaling\n",
    "    df_scaled = df.copy()\n",
    "    df_scaled = scale(df_scaled)\n",
    "    #df_scaled = minmax_scale(df_scaled)\n",
    "    cols = df.columns.tolist()\n",
    "    df_scaled = pd.DataFrame(df_scaled,columns = cols,index = df.index)\n",
    "    df = df_scaled.copy()\n",
    "    return df\n",
    "df_test = scaler_fun2(df_test)\n",
    "df_test_X = df_test.loc[:,(df_test.columns!=\"PassengerId\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_210\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1046 (Dense)           (None, 64)                768       \n",
      "_________________________________________________________________\n",
      "dropout_627 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_621 (Bat (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_1047 (Dense)           (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_628 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_622 (Bat (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_1048 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_629 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_623 (Bat (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dense_1049 (Dense)           (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_1050 (Dense)           (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 4,113\n",
      "Trainable params: 3,889\n",
      "Non-trainable params: 224\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"model_super_79.4.h5\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(df_test_X)\n",
    "y_pred = pd.DataFrame(y_pred, columns =[\"Survived\"])\n",
    "y_pred.loc[y_pred[\"Survived\"]>=0.5]=1\n",
    "y_pred.loc[y_pred[\"Survived\"]<0.5]=0\n",
    "y_pred = pd.concat([passenger_id,y_pred],axis = 1)\n",
    "y_pred = y_pred.astype(int)\n",
    "#y_pred.to_csv(\"predictionss.csv\",index = False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "titanic.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
