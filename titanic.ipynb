{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DJw_JUBmdh1Q"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout,BatchNormalization\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.optimizers import Adam,Adamax,Nadam\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from sklearn.preprocessing import scale,minmax_scale\n",
    "from tensorflow.keras import initializers, optimizers\n",
    "import io\n",
    "import requests\n",
    "import re\n",
    "import warnings\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from keras.regularizers import l2\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "df2 = df\n",
    "test_data = pd.read_csv(\"test.csv\")\n",
    "df_test=test_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    \n",
    "    #extract the title feature\n",
    "    def getMedian(df,name):\n",
    "        return df[df[\"Title\"]==name].Age.dropna().median()\n",
    "    \n",
    "    def replace_missing_age(df):\n",
    "        df.loc[(df[\"Age\"].isnull())&(df[\"Title\"]==\"Mr\"),\"Age\"] =  getMedian(df,\"Mr\") \n",
    "        df.loc[(df[\"Age\"].isnull())&(df[\"Title\"]==\"Miss\"),\"Age\"] =  getMedian(df,\"Miss\")\n",
    "        df.loc[(df[\"Age\"].isnull())&(df[\"Title\"]==\"Mrs\"),\"Age\"] =  getMedian(df,\"Mrs\")\n",
    "        df.loc[(df[\"Age\"].isnull())&(df[\"Title\"]==\"Master\"),\"Age\"] = getMedian(df,\"Master\")\n",
    "        df.loc[(df[\"Age\"].isnull())&(df[\"Title\"]==\"Rare\"),\"Age\"] =  getMedian(df,\"Rare\")\n",
    "        return df\n",
    "    \n",
    "    def title(df):\n",
    "        df['Title'] = df.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "        #print(df[\"Title\"].describe())\n",
    "        df['Title'] = df['Title'].replace(['Lady',\"Ms\",'Countess','Capt', 'Col',\\\n",
    " \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "        df = replace_missing_age(df)\n",
    "        map_title = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
    "        df[\"Title\"] = df[\"Title\"].map(map_title)\n",
    "        df[\"Title\"] = df[\"Title\"].fillna(1)\n",
    "        return df\n",
    "    \n",
    "    df = title(df)\n",
    "    \n",
    "    #dont need names and cabins had a lot of missing values so get rid of it\n",
    "    #also we dont need the ticket number\n",
    "    def drop_values(df):\n",
    "        df = df.drop(\"Cabin\",axis = 1)\n",
    "        df = df.drop(\"Name\",axis = 1)\n",
    "        df = df.drop(\"Ticket\",axis = 1)\n",
    "        return df\n",
    "    \n",
    "    df = drop_values(df)\n",
    "    \n",
    "    \n",
    "    genders = {\"male\":1,\"female\":0}\n",
    "    df[\"Sex\"] = df[\"Sex\"].map(genders)\n",
    "    \n",
    "    df[\"Embarked\"] = df[\"Embarked\"].fillna(\"S\")\n",
    "    \n",
    "    ports = {\"S\":0,\"C\":1,\"Q\":2}\n",
    "    \n",
    "    df[\"Embarked\"] = df[\"Embarked\"].map(ports)\n",
    "    \n",
    "    \n",
    "    def isalone(df):\n",
    "        df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "        df[\"isalone\"]=0\n",
    "        df.loc[df[\"FamilySize\"]==1,\"isalone\"]=1\n",
    "        #df.drop(\"FamilySize\",axis = 1)\n",
    "        return df\n",
    "    df = isalone(df)\n",
    "    def get_fares(df):\n",
    "        df.loc[df[\"Fare\"]<=7.91,\"Fare\"]=0\n",
    "        df.loc[(df[\"Fare\"]<=14)&(df[\"Fare\"]>7.91),\"Fare\"]=1\n",
    "        df.loc[(df[\"Fare\"]<=25)&(df[\"Fare\"]>14),\"Fare\"]=2\n",
    "        df.loc[(df[\"Fare\"]<=31)&(df[\"Fare\"]>25),\"Fare\"]=3\n",
    "        df.loc[(df[\"Fare\"]<=69)&(df[\"Fare\"]>31),\"Fare\"]=4\n",
    "        df.loc[(df[\"Fare\"]<=99)&(df[\"Fare\"]>69),\"Fare\"]=5\n",
    "        df.loc[(df[\"Fare\"]<=250)&(df[\"Fare\"]>99),\"Fare\"]=6\n",
    "        df.loc[df[\"Fare\"]>250,\"Fare\"]=7\n",
    "        return df\n",
    "    \n",
    "    def fare_pclass_feature(df):\n",
    "        df[\"fare*pclass\"] = df[\"Pclass\"]*df[\"Fare\"]\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    df.Fare = df.Fare.fillna(df.Fare.mean())\n",
    "    df = get_fares(df)\n",
    "    df = fare_pclass_feature(df)\n",
    "     \n",
    "    #categorises the age of the people\n",
    "    def categAge(df):\n",
    "        df.loc[df[\"Age\"]<=16,\"Age\"]=0\n",
    "        df.loc[(df[\"Age\"]>16) & (df[\"Age\"]<=32),\"Age\"] = 1\n",
    "        df.loc[(df[\"Age\"]>32) & (df[\"Age\"]<=48),\"Age\"] =2\n",
    "        df.loc[(df[\"Age\"]>48) & (df[\"Age\"]<=64),\"Age\"] =3\n",
    "        df.loc[(df[\"Age\"]>60),\"Age\"] =4\n",
    "        return df\n",
    "    df = categAge(df)\n",
    "    \n",
    "    age_dummy = pd.get_dummies(df[\"Age\"])\n",
    "    fares_dummy = pd.get_dummies(df[\"Fare\"])\n",
    "    title_dummy = pd.get_dummies(df[\"Title\"])\n",
    "    pclass_dummy = pd.get_dummies(df[\"Pclass\"])\n",
    "    sex_dummy = pd.get_dummies(df[\"Sex\"])\n",
    "    \n",
    "    #oneHot encode these variables and then drop the original ones\n",
    "    \n",
    "    df = pd.concat([df,pclass_dummy,title_dummy,sex_dummy,age_dummy],axis = 1)\n",
    "    #df = df.drop(\"Fare\",axis = 1)\n",
    "    df = df.drop(\"Pclass\",axis = 1)\n",
    "    df = df.drop(\"Age\",axis = 1)\n",
    "    df = df.drop(\"Title\",axis = 1)\n",
    "    df = df.drop(\"Sex\",axis = 1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = preprocess(df)\n",
    "df_prescaled = df.copy()\n",
    "\n",
    "def scaler_fun(df):\n",
    "    #data scaling\n",
    "    df_scaled = df.drop(\"Survived\",axis = 1)\n",
    "    df_scaled = scale(df_scaled)\n",
    "    #df_scaled = minmax_scale(df_scaled)\n",
    "    cols = df.columns.tolist()\n",
    "    cols.remove(\"Survived\")\n",
    "    df_scaled = pd.DataFrame(df_scaled,columns = cols,index = df.index)\n",
    "    df_scaled = pd.concat([df_scaled,df[\"Survived\"]],axis = 1)\n",
    "    df = df_scaled.copy()\n",
    "    return df\n",
    "\n",
    "pass_id_train = df[\"PassengerId\"].copy()\n",
    "df = scaler_fun(df)\n",
    "X = df.loc[:, (df.columns != \"Survived\") & (df.columns != \"PassengerId\")]\n",
    "Y = df.loc[:,\"Survived\"]\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size = 0.1,random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#initialise the model,\n",
    "#the kernel_initializer sets up the weights in the beginning\n",
    "#azt hiszem weight = (random sz√°m)*0.01*(2/sqrt(dimensions of input))\n",
    "#valahogy igy initializalja\n",
    "adam = Adam(learning_rate = 3E-4)\n",
    "adamax = Adamax(learning_rate = 2E-4)\n",
    "nadam = Nadam(learning_rate = 2E-4)\n",
    "model = Sequential()\n",
    "model.add(Dense(12,activation = \"relu\",input_dim= X.shape[1],kernel_regularizer = l2(0.6),kernel_initializer=\"uniform\"))\n",
    "model.add(BatchNormalization())\n",
    "# model.add(Dense(2,activation = \"relu\",kernel_initializer=\"uniform\"))\n",
    "model.add(Dropout(0.3))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(Dense(1,activation = \"relu\",kernel_initializer=\"uniform\"))\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer = adam,metrics = [\"accuracy\"])\n",
    "callback = keras.callbacks.EarlyStopping(monitor='accuracy',patience = 95)\n",
    "history = model.fit(x_train,y_train,validation_data=(x_test,y_test),epochs = 700,batch_size=400,callbacks =None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the Hyperparameter search function, I have used it but I found that changing the parameters by hand worked better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(learning_rate = 3E-4)\n",
    "def create_model(dropout=0.3,init=\"uniform\",optimizer=adam):\n",
    "    mmodel = Sequential()\n",
    "    model.add(Dense(12,activation = \"relu\",input_dim= X.shape[1],kernel_regularizer = l2(0.6),kernel_initializer=init))\n",
    "    model.add(BatchNormalization())\n",
    "    # model.add(Dense(2,activation = \"relu\",kernel_initializer=\"uniform\"))\n",
    "    model.add(Dropout(dropout))\n",
    "    # model.add(BatchNormalization())\n",
    "    model.add(Dense(1,activation = \"relu\",kernel_initializer=\"uniform\"))\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer = optimizer,metrics = [\"accuracy\"])\n",
    "    return model\n",
    "#standard setup for the Gridsearch to find Hyperparameters\n",
    "def gridsearch_fun():\n",
    "    model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "    batch_size = [400,550,800]\n",
    "    epochs = [300,500,600]\n",
    "    init = ['glorot_uniform', 'normal']\n",
    "    optimizer = [\"Adagrad\",\"Adam\"]\n",
    "    param_grid = dict(batch_size=batch_size, epochs=epochs,init = init,dropout=[0.1,0.2,0.3,0.4],optimizer = optimizer)\n",
    "    grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "    grid_result = grid.fit(X,Y)\n",
    "    # summarize results\n",
    "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    for mean, stdev, param in zip(means, stds, params):\n",
    "        print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "gridsearch_fun()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_before = df_test.copy()\n",
    "df_test =preprocess(df_test)\n",
    "passenger_id = df_test[\"PassengerId\"].copy()\n",
    "def scaler_fun2(df):\n",
    "    #data scaling\n",
    "    df_scaled = df.copy()\n",
    "    df_scaled = scale(df_scaled)\n",
    "    #df_scaled = minmax_scale(df_scaled)\n",
    "    cols = df.columns.tolist()\n",
    "    df_scaled = pd.DataFrame(df_scaled,columns = cols,index = df.index)\n",
    "    df = df_scaled.copy()\n",
    "    return df\n",
    "df_test = scaler_fun2(df_test)\n",
    "df_test_X = df_test.loc[:,(df_test.columns!=\"PassengerId\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_17 (Dense)             (None, 12)                276       \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 12)                48        \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 337\n",
      "Trainable params: 313\n",
      "Non-trainable params: 24\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"model_super79.6.h5\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(df_test_X)\n",
    "y_pred = pd.DataFrame(y_pred, columns =[\"Survived\"])\n",
    "y_pred.loc[y_pred[\"Survived\"]>=0.5]=1\n",
    "y_pred.loc[y_pred[\"Survived\"]<0.5]=0\n",
    "y_pred = pd.concat([passenger_id,y_pred],axis = 1)\n",
    "y_pred = y_pred.astype(int)\n",
    "#y_pred.to_csv(\"predictionss.csv\",index = False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "titanic.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
